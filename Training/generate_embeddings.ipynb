{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85079df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import ViTImageProcessor, ViTModel\n",
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import ast\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# --- Configuration ---\n",
    "load_dotenv(dotenv_path='../backend/.env')\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "INDEX_NAME = os.getenv(\"INDEX_NAME\")\n",
    "\n",
    "# --- File Paths & Data Loading ---\n",
    "original_csv_path = \"furniture_data.csv\"\n",
    "enriched_csv_path = \"furniture_data_enriched.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34988b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Dataset ---\n",
    "df = pd.read_csv(\"furniture_data.csv\")\n",
    "df['uniq_id'] = df['uniq_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbeec0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price_cleaned'] = df['price'].str.replace('$', '', regex=False).str.replace(',', '', regex=False)\n",
    "df['price_cleaned'] = pd.to_numeric(df['price_cleaned'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d16b253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up LLM for data enrichment using Ollama (phi3:mini)...\n",
      "Found existing enriched data at 'furniture_data_enriched.csv'. Resuming...\n",
      "Found 0 rows to enrich.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. LLM for Data Enrichment (Using Ollama) ---\n",
    "print(\"Setting up LLM for data enrichment using Ollama (phi3:mini)...\")\n",
    "# Using a local model to avoid rate limits\n",
    "llm = ChatOllama(model=\"phi3:mini\", temperature=0)\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You are a product catalog manager. Your task is to write a clean, consistent product description based on the structured data provided.\n",
    "Standardize the information and present it in a natural, descriptive paragraph.\n",
    "Use ONLY the information provided. If a piece of information (like material, color, or dimensions) is missing, do not mention it and do not invent it.\n",
    "\n",
    "Product Data:\n",
    "- Title: {title}\n",
    "- Categories: {categories}\n",
    "- Brand: {brand}\n",
    "- Material: {material}\n",
    "- Color: {color}\n",
    "- Dimensions: {dimensions}\n",
    "\n",
    "Generated Description:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"title\", \"categories\", \"brand\", \"material\", \"color\", \"dimensions\"])\n",
    "enrichment_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# --- Save and Resume Logic ---\n",
    "if os.path.exists(enriched_csv_path):\n",
    "    print(f\"Found existing enriched data at '{enriched_csv_path}'. Resuming...\")\n",
    "    enriched_df = pd.read_csv(enriched_csv_path)\n",
    "    df = pd.merge(df, enriched_df[['uniq_id', 'enriched_description']], on='uniq_id', how='left')\n",
    "else:\n",
    "    print(\"No existing enriched data found. Starting from scratch.\")\n",
    "    df['enriched_description'] = df['description']\n",
    "\n",
    "rows_to_enrich = df[df['enriched_description'].isna() | (df['enriched_description'].str.split().str.len() < 5)]\n",
    "print(f\"Found {len(rows_to_enrich)} rows to enrich.\")\n",
    "\n",
    "if not rows_to_enrich.empty:\n",
    "    print(\"Enriching product descriptions where needed...\")\n",
    "    for index, row in tqdm(rows_to_enrich.iterrows(), total=len(rows_to_enrich)):\n",
    "        try:\n",
    "            inputs = {\n",
    "                'title': row['title'] if pd.notna(row['title']) else '',\n",
    "                'categories': row['categories'] if pd.notna(row['categories']) else '',\n",
    "                'brand': row['brand'] if pd.notna(row['brand']) else '',\n",
    "                'material': row['material'] if pd.notna(row['material']) else '',\n",
    "                'color': row['color'] if pd.notna(row['color']) else '',\n",
    "                'dimensions': row['package_dimensions'] if pd.notna(row['package_dimensions']) else ''\n",
    "            }\n",
    "            response = enrichment_chain.run(inputs)\n",
    "            df.loc[index, 'enriched_description'] = response.strip()\n",
    "            \n",
    "            if (index + 1) % 10 == 0:\n",
    "                df.to_csv(enriched_csv_path, index=False)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nAn error occurred while enriching data for {row['uniq_id']}: {e}\")\n",
    "            print(\"Stopping enrichment process. Saving current progress.\")\n",
    "            break\n",
    "    \n",
    "    df.to_csv(enriched_csv_path, index=False)\n",
    "    print(\"Enrichment process finished. Final results saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb74d891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading text and image models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jatinaggarwal/Documents/GitHub/Recommendation-System/venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# --- Model Loading ---\n",
    "print(\"Loading text and image models...\")\n",
    "text_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "image_processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "image_model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "image_model.to(device)\n",
    "\n",
    "def get_image_embedding(image_url_str):\n",
    "    if pd.isna(image_url_str): return None\n",
    "    try:\n",
    "        image_urls = ast.literal_eval(image_url_str)\n",
    "        if not image_urls: return None\n",
    "        first_image_url = image_urls[0].strip()\n",
    "        image = Image.open(requests.get(first_image_url, stream=True).raw).convert('RGB')\n",
    "        inputs = image_processor(images=image, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = image_model(**inputs)\n",
    "        return outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
    "    except Exception as e:\n",
    "        print(f\"Could not process image URL {image_url_str}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3695841d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Pinecone...\n",
      "Index 'furniture-recommender' already exists.\n",
      "Pinecone setup complete.\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Pinecone Setup ---\n",
    "print(\"Initializing Pinecone...\")\n",
    "from pinecone import Pinecone\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Create index if it doesn't exist\n",
    "if INDEX_NAME not in pc.list_indexes().names():\n",
    "    print(f\"Creating index '{INDEX_NAME}'...\")\n",
    "    # Import ServerlessSpec right before it's used to avoid NameError\n",
    "    from pinecone import ServerlessSpec\n",
    "    \n",
    "    # Text embedding dim (384) + Image embedding dim (768)\n",
    "    pc.create_index(\n",
    "        name=INDEX_NAME,\n",
    "        dimension=384 + 768,\n",
    "        metric='cosine',\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws',\n",
    "            region='us-east-1'\n",
    "        )\n",
    "    )\n",
    "    print(\"Index created successfully.\")\n",
    "else:\n",
    "    print(f\"Index '{INDEX_NAME}' already exists.\")\n",
    "\n",
    "index = pc.Index(INDEX_NAME)\n",
    "print(\"Pinecone setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196ef379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating and upserting embeddings to Pinecone...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [01:47<00:00,  9.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished upserting embeddings.\n",
      "{'dimension': 1152,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 305}},\n",
      " 'total_vector_count': 305}\n"
     ]
    }
   ],
   "source": [
    "# --- Generate and Upsert Embeddings ---\n",
    "print(\"Generating and upserting embeddings to Pinecone...\")\n",
    "batch_size = 32\n",
    "\n",
    "for i in tqdm(range(0, len(df), batch_size)):\n",
    "    batch = df.iloc[i:i+batch_size]\n",
    "    \n",
    "    # Create text for embeddings from the title and the new ENRICHED description\n",
    "    text_for_embeddings = (batch['title'].fillna('') + \". \" + batch['enriched_description'].fillna('')).tolist()\n",
    "    text_embeddings = text_model.encode(text_for_embeddings).tolist()\n",
    "    \n",
    "    image_embeddings = [get_image_embedding(url) for url in batch['images']]\n",
    "    \n",
    "    vectors_to_upsert = []\n",
    "    for idx, row in enumerate(batch.itertuples()):\n",
    "        img_emb = image_embeddings[idx]\n",
    "        if img_emb is not None:\n",
    "            combined_embedding = text_embeddings[idx] + img_emb.tolist()\n",
    "            try:\n",
    "                first_image = ast.literal_eval(row.images)[0].strip()\n",
    "            except:\n",
    "                first_image = ''\n",
    "            price_str = f\"${row.price_cleaned:.2f}\" if pd.notna(row.price_cleaned) else \"Price not available\"\n",
    "            # Use the enriched description in the metadata\n",
    "            metadata = {\n",
    "                'title': str(row.title) if pd.notna(row.title) else '',\n",
    "                'description': str(row.enriched_description) if pd.notna(row.enriched_description) else '',\n",
    "                'image': first_image,\n",
    "                'price': price_str,\n",
    "                'categories': str(row.categories) if pd.notna(row.categories) else '',\n",
    "                'brand': str(row.brand) if pd.notna(row.brand) else '',\n",
    "                'material': str(row.material) if pd.notna(row.material) else '',\n",
    "                'color': str(row.color) if pd.notna(row.color) else '',\n",
    "                'package_dimensions': str(row.package_dimensions) if pd.notna(row.package_dimensions) else ''\n",
    "            }\n",
    "            vectors_to_upsert.append((row.uniq_id, combined_embedding, metadata))\n",
    "            \n",
    "    if vectors_to_upsert:\n",
    "        index.upsert(vectors=vectors_to_upsert)\n",
    "\n",
    "print(\"Finished upserting embeddings.\")\n",
    "print(index.describe_index_stats())\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
